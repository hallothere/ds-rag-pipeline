{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0e5a20",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929ccfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.27.1-cp310-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.27.1-cp310-abi3-win_amd64.whl (19.2 MB)\n",
      "   ---------------------------------------- 0.0/19.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/19.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/19.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/19.2 MB 1.2 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 0.8/19.2 MB 1.2 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 1.3/19.2 MB 1.4 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 1.8/19.2 MB 1.6 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 2.1/19.2 MB 1.7 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 2.4/19.2 MB 1.6 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 2.9/19.2 MB 1.6 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 3.4/19.2 MB 1.7 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 3.7/19.2 MB 1.7 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 4.2/19.2 MB 1.8 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 4.7/19.2 MB 1.8 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 5.2/19.2 MB 1.8 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 5.2/19.2 MB 1.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 5.5/19.2 MB 1.7 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 5.8/19.2 MB 1.7 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 6.0/19.2 MB 1.7 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 6.6/19.2 MB 1.7 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 6.8/19.2 MB 1.7 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 7.3/19.2 MB 1.7 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 7.9/19.2 MB 1.8 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 8.4/19.2 MB 1.8 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 8.7/19.2 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 9.2/19.2 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 9.4/19.2 MB 1.8 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 10.0/19.2 MB 1.8 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 10.2/19.2 MB 1.8 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 10.7/19.2 MB 1.8 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 11.0/19.2 MB 1.8 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 11.0/19.2 MB 1.8 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 11.3/19.2 MB 1.7 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 11.5/19.2 MB 1.7 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 12.1/19.2 MB 1.7 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 12.3/19.2 MB 1.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 12.6/19.2 MB 1.7 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 13.1/19.2 MB 1.7 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 13.4/19.2 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 13.9/19.2 MB 1.7 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 14.4/19.2 MB 1.7 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 14.7/19.2 MB 1.8 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 15.2/19.2 MB 1.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 15.5/19.2 MB 1.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 16.0/19.2 MB 1.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 16.3/19.2 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 16.5/19.2 MB 1.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 16.8/19.2 MB 1.8 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 17.6/19.2 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 17.8/19.2 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 18.4/19.2 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  19.1/19.2 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.2/19.2 MB 1.8 MB/s  0:00:10\n",
      "Installing collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.27.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c2928e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Inbal\\Desktop\\PM Inbal\\aipm_course_exercises\\ds-rag-pipeline\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain import hub\n",
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a383a5cd",
   "metadata": {},
   "source": [
    "### 1) Extract text + images from a PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1610a3fb",
   "metadata": {},
   "source": [
    "This produces:\n",
    "\n",
    "page text as Documents\n",
    "\n",
    "images saved to disk + “image documents” (we’ll store a placeholder description now, and you can upgrade to OCR later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0344c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_images(pdf_path, image_dir=\"../extracted_images\"):\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    text_docs = []\n",
    "    image_docs = []\n",
    "\n",
    "    for page_idx in range(len(doc)):\n",
    "        page = doc[page_idx]\n",
    "\n",
    "        # ---- Text ----\n",
    "        text = page.get_text(\"text\").strip()\n",
    "        if text:\n",
    "            text_docs.append(Document(\n",
    "                page_content=text,\n",
    "                metadata={\"source\": pdf_path, \"page\": page_idx, \"type\": \"text\"}\n",
    "            ))\n",
    "\n",
    "        # ---- Images ----\n",
    "        images = page.get_images(full=True)\n",
    "        for img_i, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base = doc.extract_image(xref)\n",
    "            img_bytes = base[\"image\"]\n",
    "            ext = base.get(\"ext\", \"png\")\n",
    "\n",
    "            img_filename = f\"{os.path.basename(pdf_path).replace('.pdf','')}_p{page_idx}_img{img_i}.{ext}\"\n",
    "            img_path = os.path.join(image_dir, img_filename)\n",
    "\n",
    "            with open(img_path, \"wb\") as f:\n",
    "                f.write(img_bytes)\n",
    "\n",
    "            # For now: store a retrievable “image doc” as text (metadata points to the file)\n",
    "            image_docs.append(Document(\n",
    "                page_content=f\"[IMAGE] File: {img_filename}. Page: {page_idx}. (No caption/OCR yet.)\",\n",
    "                metadata={\"source\": pdf_path, \"page\": page_idx, \"type\": \"image\", \"image_path\": img_path}\n",
    "            ))\n",
    "\n",
    "    return text_docs, image_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ef67fa",
   "metadata": {},
   "source": [
    "### 2) Chunk the text docs (images don’t need chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23247698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text_docs(text_docs, chunk_size=1000, chunk_overlap=150):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    return splitter.split_documents(text_docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb5d69",
   "metadata": {},
   "source": [
    "### 3) Embed + store in FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1026a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vectorstore(docs, db_path=\"../vector_databases/vector_db_multimodal\"):\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "\n",
    "    vs = FAISS.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        distance_strategy=DistanceStrategy.COSINE\n",
    "    )\n",
    "    vs.save_local(db_path)\n",
    "    return vs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb2adc",
   "metadata": {},
   "source": [
    "### 4) Retrieval + generation chain (Groq LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c426cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rag_chain(vectorstore, llm):\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "    stuff_chain = create_stuff_documents_chain(\n",
    "        llm=llm,\n",
    "        prompt=hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "    )\n",
    "    rag_chain = create_retrieval_chain(retriever=retriever, combine_docs_chain=stuff_chain)\n",
    "    return rag_chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f393f17",
   "metadata": {},
   "source": [
    "### 5) run it end to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9207c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../documents/crs_external_products.pdf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.congress.gov/crs_external_products/R/PDF/R43419/R43419.98.pdf\"\n",
    "local_path = \"../documents/crs_external_products.pdf\"\n",
    "\n",
    "r = requests.get(url)\n",
    "with open(local_path, \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "print(\"Saved:\", local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eb722d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document appears to be a table or chart comparing NASA's appropriations for various years, specifically for the Construction and EC&R (Engineering, Construction, and Research) and Inspector General categories. The table shows the appropriations for FY2023, FY2024 (requested), and FY2024 (House Introduced and Senate Committee versions).\n",
      "\n",
      "I saw the following figures/images:\n",
      "\n",
      "- A series of numbers (3,369, 3,136, 3,100) at the top of the table, but their context is unclear.\n",
      "- A table with the following categories:\n",
      "  - Construction and EC&R\n",
      "  - Inspector General\n",
      "  - Total\n",
      "- The table shows the appropriations for FY2023, FY2024 (requested), and FY2024 (House Introduced and Senate Committee versions).\n",
      "- There are also references to images (crs_external_products_p6_img0.png, crs_external_products_p0_img1.png, crs_external_products_p0_img0.png) but no captions or OCR (Optical Character Recognition) text is available for these images.\n",
      "\n",
      "The document also mentions sources for the data, including congressional budget justifications and explanatory statements.\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"../documents/crs_external_products.pdf\" \n",
    "text_docs, image_docs = extract_text_and_images(pdf_path)\n",
    "\n",
    "text_chunks = chunk_text_docs(text_docs)\n",
    "all_docs = text_chunks + image_docs\n",
    "\n",
    "vectorstore = build_vectorstore(all_docs, db_path=\"../vector_databases/vector_db_multimodal_v1\")\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
    "\n",
    "rag_chain = build_rag_chain(vectorstore, llm)\n",
    "\n",
    "out = rag_chain.invoke({\"input\": \"Summarize the document and mention any figures/images you saw.\"})\n",
    "print(out[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03ea0e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "אני לא בטוח שאני יכול לספק תשובה מדויקת, אך נראה שהדוקומנט הזה עוסק בתקציב של נאס\"א (NASA) לשנים שונות, ומפרט את התקציבים השונים לתחומים שונים, כגון: \n",
      "\n",
      "* אסטרופיזיקה\n",
      "* תחנת החלל הבינלאומית\n",
      "* חקר החלל\n",
      "* פיתוח וייצור\n",
      "* תקציבי חירום\n",
      "\n",
      "בסך הכל, הדוקומנט נראה שהוא תיעוד של התקציבים של נאס\"א לשנים שונות, ומספק פרטים על התקציבים השונים לתחומים שונים.\n",
      "\n",
      "תרגום: \n",
      "\"אני לא בטוח\" - \"I'm not sure\"\n",
      "\"נאס\"א\" - \"NASA\"\n",
      "\"תקציב\" - \"budget\"\n",
      "\"תחומים\" - \"fields\"\n",
      "\"חירום\" - \"emergency\"\n"
     ]
    }
   ],
   "source": [
    "out = rag_chain.invoke({\"input\": \"what is this document about? answer in hebrew\"\n",
    "\"\"})\n",
    "print(out[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7e84f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow in C:\\Users\\Inbal\\Desktop\\PM Inbal\\aipm_course_exercises\\ds-rag-pipeline\\.venv\\Lib\\site-packages (12.1.1)\n",
      "Requirement already satisfied: packaging>=21.3 in C:\\Users\\Inbal\\Desktop\\PM Inbal\\aipm_course_exercises\\ds-rag-pipeline\\.venv\\Lib\\site-packages (from pytesseract) (24.2)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bf3dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f16bdd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crs_external_products_p0_img0.png',\n",
       " 'crs_external_products_p0_img1.png',\n",
       " 'crs_external_products_p6_img0.png',\n",
       " 'pilates_mat_basic_p0_img0.png',\n",
       " 'pilates_mat_basic_p0_img1.png',\n",
       " 'pilates_mat_basic_p0_img10.png',\n",
       " 'pilates_mat_basic_p0_img100.png',\n",
       " 'pilates_mat_basic_p0_img101.png',\n",
       " 'pilates_mat_basic_p0_img11.png',\n",
       " 'pilates_mat_basic_p0_img12.png',\n",
       " 'pilates_mat_basic_p0_img13.png',\n",
       " 'pilates_mat_basic_p0_img14.png',\n",
       " 'pilates_mat_basic_p0_img15.png',\n",
       " 'pilates_mat_basic_p0_img16.png',\n",
       " 'pilates_mat_basic_p0_img17.png',\n",
       " 'pilates_mat_basic_p0_img18.png',\n",
       " 'pilates_mat_basic_p0_img19.png',\n",
       " 'pilates_mat_basic_p0_img2.png',\n",
       " 'pilates_mat_basic_p0_img20.png',\n",
       " 'pilates_mat_basic_p0_img21.png',\n",
       " 'pilates_mat_basic_p0_img22.png',\n",
       " 'pilates_mat_basic_p0_img23.png',\n",
       " 'pilates_mat_basic_p0_img24.png',\n",
       " 'pilates_mat_basic_p0_img25.png',\n",
       " 'pilates_mat_basic_p0_img26.png',\n",
       " 'pilates_mat_basic_p0_img27.png',\n",
       " 'pilates_mat_basic_p0_img28.png',\n",
       " 'pilates_mat_basic_p0_img29.png',\n",
       " 'pilates_mat_basic_p0_img3.png',\n",
       " 'pilates_mat_basic_p0_img30.png']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"../extracted_images\")[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6986d61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 Dollars\n",
      "\n",
      "Current Dollars\n",
      "\n",
      "40\n",
      "\n",
      "35\n",
      "\n",
      "30\n",
      "\n",
      "ra) ° i)\n",
      "N a a\n",
      "\n",
      "(suoying $) Asouiny y88png\n",
      "\n",
      "10\n",
      "\n",
      "raara\n",
      "07207\n",
      "8107\n",
      "9T0Z\n",
      "vtoz\n",
      "casera\n",
      "OTOz\n",
      "8007\n",
      "9007\n",
      "007\n",
      "7007\n",
      "0007\n",
      "866T\n",
      "966T\n",
      "v66T\n",
      "766T\n",
      "O66T\n",
      "886T\n",
      "986T\n",
      "v86T\n",
      "786T\n",
      "O86T\n",
      "8Z46T\n",
      "9Z6T\n",
      "vet\n",
      "tL6T\n",
      "OL6T\n",
      "896T\n",
      "996T\n",
      "v96T\n",
      "796T\n",
      "O96T\n",
      "8S6T\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "img_path = \"../extracted_images/crs_external_products_p6_img0.png\"\n",
    "\n",
    "text = pytesseract.image_to_string(Image.open(img_path))\n",
    "print(text[:2500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a049bb",
   "metadata": {},
   "source": [
    "### 1) Extraction (text + images + OCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f057fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from langchain.schema import Document\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def extract_text_and_ocr_images(pdf_path, image_dir=\"../extracted_images_fairytale\"):\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "    pdf = fitz.open(pdf_path)\n",
    "\n",
    "    text_docs = []\n",
    "    ocr_image_docs = []\n",
    "\n",
    "    for page_idx in range(len(pdf)):\n",
    "        page = pdf[page_idx]\n",
    "\n",
    "        # ---- Text ----\n",
    "        text = page.get_text(\"text\").strip()\n",
    "        if text:\n",
    "            text_docs.append(Document(\n",
    "                page_content=text,\n",
    "                metadata={\"source\": pdf_path, \"page\": page_idx, \"type\": \"text\"}\n",
    "            ))\n",
    "\n",
    "        # ---- Images + OCR ----\n",
    "        images = page.get_images(full=True)\n",
    "        for img_i, img in enumerate(images):\n",
    "            xref = img[0]\n",
    "            base = pdf.extract_image(xref)\n",
    "            img_bytes = base[\"image\"]\n",
    "            ext = base.get(\"ext\", \"png\")\n",
    "\n",
    "            img_filename = f\"{os.path.basename(pdf_path).replace('.pdf','')}_p{page_idx}_img{img_i}.{ext}\"\n",
    "            img_path = os.path.join(image_dir, img_filename)\n",
    "\n",
    "            with open(img_path, \"wb\") as f:\n",
    "                f.write(img_bytes)\n",
    "\n",
    "            ocr_text = pytesseract.image_to_string(Image.open(img_path)).strip()\n",
    "            content = ocr_text if ocr_text else \"Illustration detected (no readable text via OCR).\"\n",
    "\n",
    "            ocr_image_docs.append(Document(\n",
    "                page_content=f\"[IMAGE_OCR]\\n{content}\",\n",
    "                metadata={\"source\": pdf_path, \"page\": page_idx, \"type\": \"image_ocr\", \"image_path\": img_path}\n",
    "            ))\n",
    "\n",
    "    return text_docs, ocr_image_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e950c7e",
   "metadata": {},
   "source": [
    "### 2) Chunking + Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a381ef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "def chunk_docs(docs, chunk_size=1000, chunk_overlap=150):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_documents(docs)\n",
    "\n",
    "def build_vectorstore(docs, db_path=\"../vector_databases/vector_db_fairytale_mmocr\"):\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "        encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "    vs = FAISS.from_documents(docs, embeddings, distance_strategy=DistanceStrategy.COSINE)\n",
    "    vs.save_local(db_path)\n",
    "    return vs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e720f9a3",
   "metadata": {},
   "source": [
    "### 3) RAG chain (retrieval + Groq generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50a9f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain import hub\n",
    "from langchain.chains.combine_documents.stuff import create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "def build_rag_chain(vectorstore):\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
    "\n",
    "    stuff_chain = create_stuff_documents_chain(llm=llm, prompt=hub.pull(\"langchain-ai/retrieval-qa-chat\"))\n",
    "    return create_retrieval_chain(retriever=retriever, combine_docs_chain=stuff_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383516f5",
   "metadata": {},
   "source": [
    "### 4) Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c75a0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary:**\n",
      "\n",
      "The story is about a king's daughter who loses her golden ball into a well in the forest. A frog helps her retrieve the ball, and in return, she promises to marry him if he helps her. However, the frog is actually a prince who has been cursed by a witch. The princess's kindness and love break the curse, and the frog transforms back into a prince. They get married, and the prince's servant, Faithful Henry, is overjoyed to see his master happy and free.\n",
      "\n",
      "**Illustration:**\n",
      "\n",
      "Unfortunately, there is no specific illustration provided in the given context. However, based on the story, a possible illustration could show the princess and the prince (formerly a frog) sitting together, smiling, and holding hands. The illustration might also depict Faithful Henry in the background, looking happy and relieved. Alternatively, it could show the princess and the prince in their carriage, with Faithful Henry standing behind them, as described in the story.\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"../documents/The_Frog-King.pdf\"  # replace\n",
    "text_docs, ocr_docs = extract_text_and_ocr_images(pdf_path)\n",
    "\n",
    "text_chunks = chunk_docs(text_docs)\n",
    "all_docs = text_chunks + ocr_docs\n",
    "\n",
    "vs = build_vectorstore(all_docs)\n",
    "rag_chain = build_rag_chain(vs)\n",
    "\n",
    "out = rag_chain.invoke({\"input\": \"Summarize the story and describe what the illustration shows.\"})\n",
    "print(out[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e83af476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = \"../documents/The_Frog-King.pdf\"\n",
    "text_docs, ocr_docs = extract_text_and_ocr_images(pdf_path)\n",
    "len(text_docs), len(ocr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe8f19d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are two illustrations detected, but no readable text via OCR.\n",
      "\n",
      "--- CONTEXT DOC ---\n",
      "{'source': '../documents/The_Frog-King.pdf', 'page': 3, 'type': 'text'}\n",
      "But when she was in bed he crept to her and said, \"I am tired, I want to sleep as well as thou, lift me\n",
      "up or I will tell thy father.\" Then she was terribly angry, and took him up and threw him with all her\n",
      "might against the wall. \"Now, thou wilt be quiet, odious frog,\" said she. But when he fell do\n",
      "\n",
      "--- CONTEXT DOC ---\n",
      "{'source': '../documents/The_Frog-King.pdf', 'page': 0, 'type': 'image_ocr', 'image_path': '../extracted_images_fairytale\\\\The_Frog-King_p0_img0.jpeg'}\n",
      "[IMAGE_OCR]\n",
      "Illustration detected (no readable text via OCR).\n",
      "\n",
      "--- CONTEXT DOC ---\n",
      "{'source': '../documents/The_Frog-King.pdf', 'page': 2, 'type': 'image_ocr', 'image_path': '../extracted_images_fairytale\\\\The_Frog-King_p2_img0.jpeg'}\n",
      "[IMAGE_OCR]\n",
      "Illustration detected (no readable text via OCR).\n",
      "\n",
      "--- CONTEXT DOC ---\n",
      "{'source': '../documents/The_Frog-King.pdf', 'page': 0, 'type': 'text'}\n",
      "The frog answered, \"I do not care for thy clothes, thy pearls and jewels, or thy golden crown, but\n",
      "if thou wilt love me and let me be thy companion and play-fellow, and sit by thee at thy little table,\n",
      "and eat off thy little golden plate, and drink out of thy little cup, and sleep in thy little bed—\n",
      "\n",
      "--- CONTEXT DOC ---\n",
      "{'source': '../documents/The_Frog-King.pdf', 'page': 1, 'type': 'text'}\n",
      "When the frog was once on the chair he wanted to be on the table, and when he was on the table he\n",
      "said, \"Now, push thy little golden plate nearer to me that we may eat together.\" She did this, but it was\n",
      "easy to see that she did not do it willingly. The frog enjoyed what he ate, but almost every mou\n"
     ]
    }
   ],
   "source": [
    "out = rag_chain.invoke({\"input\": \"What illustrations are included and on which pages? Use ONLY the provided context.\"})\n",
    "\n",
    "print(out[\"answer\"])\n",
    "\n",
    "for d in out[\"context\"]:\n",
    "    print(\"\\n--- CONTEXT DOC ---\")\n",
    "    print(d.metadata)\n",
    "    print(d.page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7b6db09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 0: 1 embedded images\n",
      "Page 1: 0 embedded images\n",
      "Page 2: 1 embedded images\n",
      "Page 3: 0 embedded images\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "\n",
    "pdf_path = \"../documents/The_Frog-King.pdf\"\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "for p in range(len(doc)):\n",
    "    imgs = doc[p].get_images(full=True)\n",
    "    print(f\"Page {p}: {len(imgs)} embedded images\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
